{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结合之前所学\n",
    "\n",
    "在前一个 Notebook 中，或许你已经猜到了，使用所有特征可能会让模型出现过拟合。R 平方虽然能告诉你，模型在训练集上拟合得很好，但它没法预测模型在测试集上的表现。\n",
    "\n",
    "在本次 Notebook 里，我们将继续之前的练习。首先读取数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import AllTogether as t\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('./survey_results_public.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "**1.** 将下面的字母变量替换到 format() 内的正确位置。注意，字符串中每个 **{}** 都对应一个变量的值。整段话讲述的正是我们之前了解到的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'test_score'\n",
    "b = 'train_score'\n",
    "c = 'linear model (lm_model)'\n",
    "d = 'X_train and y_train'\n",
    "e = 'X_test'\n",
    "f = 'y_test'\n",
    "g = 'train and test data sets'\n",
    "h = 'overfitting'\n",
    "\n",
    "q1_piat = '''In order to understand how well our {} fit the dataset, \n",
    "            we first needed to split our data into {}.  \n",
    "            Then we were able to fit our {} on the {}.  \n",
    "            We could then predict using our {}  by providing \n",
    "            the linear model the {} for it to make predictions.  \n",
    "            These predictions were for {}. \n",
    "\n",
    "            By looking at the {}, it looked like we were doing awesome because \n",
    "            it was 1!  However, looking at the {} suggested our model was not \n",
    "            extending well.  The purpose of this notebook will be to see how \n",
    "            well we can get our model to extend to new data.\n",
    "            \n",
    "            This problem where our data fits the training data well, but does\n",
    "            not perform well on test data is commonly known as \n",
    "            {}.'''.format(a, a, a, a, a, a, a, a, a, a) #replace a with the correct variable\n",
    "\n",
    "print(q1_piat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the solution order of the letters in the format\n",
    "t.q1_piat_answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "**2.** 现在，我们要改进模型。判断字典里关于优化模型的陈述是否正确。**每一句陈述都是独立的**。在判断的时候，也可以一边思考哪些是有用的**下一步**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'yes'\n",
    "b = 'no'\n",
    "\n",
    "q2_piat = {'add interactions, quadratics, cubics, and other higher order terms': #letter here, \n",
    "           'fit the model many times with different rows, then average the responses': #letter here,\n",
    "           'subset the features used for fitting the model each time': #letter here,\n",
    "           'this model is hopeless, we should start over': #letter here}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check your solution\n",
    "t.q2_piat_check(q2_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "\n",
    "**3.** 在进入下一步之前，根据函数给的步骤来创建模型需要的 X 和 y。如果你的答案是对的，应该能看到跟视频中相似的图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "    \n",
    "    OUTPUT\n",
    "    X - A matrix holding all of the variables you want to consider when predicting the response\n",
    "    y - the corresponding response vector\n",
    "    \n",
    "    Perform to obtain the correct X and y objects\n",
    "    This function cleans df using the following steps to produce X and y:\n",
    "    1. Drop all the rows with no salaries\n",
    "    2. Create X as all the columns that are not the Salary column\n",
    "    3. Create y as the Salary column\n",
    "    4. Drop the Salary, Respondent, and the ExpectedSalary columns from X\n",
    "    5. For each numeric variable in X, fill the column with the mean value of the column.\n",
    "    6. Create dummy columns for all the categorical variables in X, drop the original columns\n",
    "    '''\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "#Use the function to create X and y\n",
    "X, y = clean_data(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行下面的单元格，利用得到的结果来回答 Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoffs here pertains to the number of missing values allowed in the used columns.\n",
    "#Therefore, lower values for the cutoff provides more predictors in the model.\n",
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 25]\n",
    "\n",
    "#Run this cell to pass your X and y to the model for testing\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = t.find_optimal_lm_mod(X, y, cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "**4.** 利用前面的结果和图表，将下面的字母变量跟 **q4_piat** 字典中的陈述匹配起来。注意，上面仅给出了最优的模型结果，保存在这些变量中：**lm_model**、**X_train**、**X_test**、**y_train**、**y_test**。如果一个陈述有多个答案与之对应，那么将这些字母按照字母排序放在一个括号里，组成一个元组，比如 `(a,b)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for your computations to answer the next question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'we would likely have a better rsquared for the test data.'\n",
    "b = 1000\n",
    "c = 872\n",
    "d = 0.69\n",
    "e = 0.82\n",
    "f = 0.88\n",
    "g = 0.72\n",
    "h = 'we would likely have a better rsquared for the training data.'\n",
    "\n",
    "q4_piat = {'The optimal number of features based on the results is': #letter here, \n",
    "               'The model we should implement in practice has a train rsquared of': #letter here, \n",
    "               'The model we should implement in practice has a test rsquared of': #letter here,\n",
    "               'If we were to allow the number of features to continue to increase': #letter here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check against your solution\n",
    "t.q4_piat_check(q4_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "\n",
    "**5.** sklearn 中线性回归模型应用于系数的默认惩罚是岭回归（也被称为 L2 正则化）。因为存在这种惩罚并且所有变量都进行了标准化，我们可以查看模型中系数的大小，了解每个特征变量对目标变量的影响程度。特征变量的系数越大，说明该特征对目标变量的影响也越大。\n",
    "\n",
    "利用以下单元格来查看系数，根据结果在下方字典 **q5_piat** 的陈述后面对应标注 **True** 或 **False**。\n",
    "\n",
    "#### 运行以下单元格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df\n",
    "\n",
    "#Use the function\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "#A quick look at the top results\n",
    "coef_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = True\n",
    "b = False\n",
    "\n",
    "#According to the data...\n",
    "q5_piat = {'Country appears to be one of the top indicators for salary': #letter here,\n",
    "               'Gender appears to be one of the indicators for salary': #letter here, \n",
    "               'How long an individual has been programming appears to be one of the top indicators for salary': #letter here,\n",
    "               'The longer an individual has been programming the more they are likely to earn': #letter here}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.q5_piat_check(q5_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 恭喜你\n",
    "\n",
    "希望这个练习有帮助到你温习旧知识，熟悉如何将步骤汇总进行分析。在下一课中，你将学习如何将分析结果展示给他人，帮助其展开行动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
